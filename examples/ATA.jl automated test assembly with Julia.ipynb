{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ATA.jl automated test assembly with Julia.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Julia 1.6","language":"julia","name":"julia-1.6"},"language_info":{"file_extension":".jl","mimetype":"application/julia","name":"julia","version":"1.6.0"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tQ1r1bbb0yBv"},"source":["# <img src=\"https://github.com/JuliaLang/julia-logo-graphics/raw/master/images/julia-logo-color.png\" height=\"100\" /> \n","\n","\n","This notebook is a **tutorial for assemblying psychometric tests using the package `ATA.jl`**.\n","\n","You can either run this notebook in Google Colab, or using Jupyter on your own machine."]},{"cell_type":"markdown","metadata":{"id":"f_1dr-2W5iSU"},"source":["# Getting Started with Julia in Colab/Jupyter\n"]},{"cell_type":"markdown","metadata":{"id":"6ew60wXrZM0W"},"source":["If you have `Julia` installed locally, I suggest you to copy the code in this notebook and run it in your machine.\n","Otherwise, if you prefer to use a hosted Google machine, follow these steps:\n","\n","1. Work on a copy of this notebook: _File_ > _Save a copy in Drive_ (you will need a Google account). Alternatively, you can download the notebook using _File_ > _Download .ipynb_, then upload it to [Colab](https://colab.research.google.com/).\n","2. Execute the following cell (click on it and press Ctrl+Enter) to install Julia, IJulia (the Jupyter kernel for Julia) and other packages needed in this tutorial (DataFrames, CSV, Distributions, JLD2, ATA, Psychometrics). Installation takes 2-3 minutes. ATA.jl package now works with `Julia 1.6.0`.\n","3. After you run the cell (the cell directly below this text), go to Colab's menu bar and select Runtime -> Change type of runtime and select Julia 1.6 in Runtime type from the drop down menu. You can also select your prefered hardware acceleration (defaults to GPU).\n","\n","* _Note_: If your Colab Runtime gets reset (e.g., due to inactivity), repeat steps 2 and 3."]},{"cell_type":"code","metadata":{"id":"GIeFXS0F0zww"},"source":["%%capture\n","%%shell\n","if ! command -v julia 3>&1 > /dev/null\n","then\n","    wget -q 'https://julialang-s3.julialang.org/bin/linux/x64/1.6/julia-1.6.0-linux-x86_64.tar.gz' \\\n","        -O /tmp/julia.tar.gz\n","    tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n","    rm /tmp/julia.tar.gz\n","fi\n","julia -e 'using Pkg; pkg\"add IJulia; precompile;\"'\n","echo 'Done'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxNkXvgARr84"},"source":["## Install Required Packages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yxCyOIbpRwBU","executionInfo":{"status":"ok","timestamp":1619127245396,"user_tz":-120,"elapsed":10202,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"9ffcdfaf-616a-4858-dd84-4b6e6489d442"},"source":["using Pkg\n","Pkg.add(\"CSV\")\n","Pkg.add(\"DataFrames\")\n","Pkg.add(\"JLD2\")\n","Pkg.add(\"HTTP\")\n","Pkg.add(\"StatsBase\")\n","Pkg.add(PackageSpec(url=\"https://github.com/giadasp/Psychometrics.jl\", rev=\"master\")) \n","Pkg.add(PackageSpec(url=\"https://github.com/giadasp/ATA.jl\", rev=\"master\")) "],"execution_count":24,"outputs":[{"output_type":"stream","text":["\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/giadasp/Psychometrics.jl`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n","\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/giadasp/ATA.jl`\n","\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n","\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"DUGTm5aPG6CW"},"source":["## Collect Required Settings and Data"]},{"cell_type":"markdown","metadata":{"id":"6Bzl8OA_G094"},"source":["Before starting to build our automated test assembly (ATA) model, we need to prepare the following information (? = optional):\n","\n","- 🔧__ATA Generic Settings and/or Specifications__:\n"," - `n_groups`: Number of test groups. The tests inside a group are parallel with respect to constraints and objectives. Having more than group is useful for assemblying multi-stage test (MST) modules.\n"," - `groups`: Groups' names;\n"," - `T`: Number of tests to assemble for each test group.\n"," - `n_items`: Number of items in the item bank (not grouped by friend sets).\n"," - `?irt_model`: Item Response Theory (IRT) settings are required for objectives which works on the Test Information Function (TIF), or if some Item Characteristic Function (ICF) must be computed. 1-parameter logistic (`\"1PL\"`), 2-parameter logistic (`\"2PL\"`), and 3-parameter logistic (`\"3PL\"`) are supported. Default is `\"1PL\"`.\n"," - `?irt_parametrization`: How ability (t) and difficulty (b) and discrimination (a) are linked in the model. `\"at-ab\"`, `\"at-b\"`, `\"at+ab\"`, `\"at+b\"` are supported. Default is `\"at-ab\"`.\n"," - `?irt_D`: The $D$ constant in IRT models. Default is `1.0`.\n"," - `?enemy_sets_var`: The names of the columns in the item bank which stores the enemy sets, i.e. the sets of items which cannot be chosen in the same test.\n"," - `?friend_sets_var`: The names of the columns in the item bank which stores the friend sets. Also called \"units\", they are the sets of items which must be chosen together.\n"," - `item_use_min`: A vector of length `n_items` which says in how many tests each item must be selected at least. If friend sets are specified, the maximum among all the minimum item use in the same friend sets is chosen.\n","  - `item_use_max`: A vector of length `n_items` which says in how many tests each item must be selected at most. If friend sets are specified, the minimum among all the maximum item use in the same friend sets is chosen.\n"," - `length_min`: For each group, specifies the minimum length of the tests.\n"," - `length_max`: For each group, specifies the maximum length of the tests.\n"," - `length_weight`: For the siman solver, it specifies the weight on length constraints. `1.0` is suggested as a starting point. If the solver struggles in finding a solution which satisfies length constraints, increase the weights.\n"," - `?expected_score_var`: If the item bank already contains the item characteristic function (ICF) computed at one ability point or classical theory expected scores (probability of correct answer), you can provide the name of the columns containing this information using this setting. Only one column (so only one ability point) per group can be provided in this way. \n"," - `?expected_score_pts`: Otherwise, if the expected scores or ICFs haven't been computed yet, the ability points in which you want them to be computed. By this setting, the ICFs (or expected scores) can be constrained in more than one ability point.\n"," - `?expected_score_min`: Required if `expected_score_var` or `expected_score_pts` have been specified. For each group (and for each ability point if `expected_score_pts` have been specified), the lower bound for the average ICFs (or expected score).\n"," - `?expected_score_max`: For each group (and for each ability point if `expected_score_pts` have been specified), the upper bound for the average ICFs (or expected score).  _Ex: For group 1, the tests mut have an expected score higher than 0.5._\n"," - `?mean_vars`: Only for siman solver, **still not implemented**. Until this feature is not available, and only if the expected score constraints are not needed, the mean value of a quantitative variable in the item bank can be constrained by providing its name by the `expected_score` settings (using the var, min and max settings).\n"," - `?mean_vars_min`: Only for siman solver, **still not implemented**. For each test group, the lower bound for the average of a certain quantitative variable provided by the item bank.\n"," - `?mean_vars`: Only for siman solver, **still not implemented**. For each test group, the upper bound for the average of a certain quantitative variable provided by the item bank.\n"," - `obj_type`: The objective type. Here the list of supported ATA objectives:\n","   - `\"maximin\"`: maximizes the minimum across the tests of the test information function (TIF) at predefined ability points, \n","   - `\"minimax\"`: minimizes the maximum distance across the tests between targets and TIFs,\n","   - `\"cc_maximin\"`: only for siman solver, maximizes the minimum across the tests of the $\\alpha$ quantile of the TIF (Spaccapanico P. et al. (2021), under review, chance-constrained approach, it requires a `Psychometrics` object with samples of item parameter estimates stored in the `chain` field.),\n","   - `\"soyster_maximin\"`: maximizes the minimum across the tests of the mean across item parameters samples corrected by 3 standard deviations of the TIF  (Soyster (1973) approach, it requires a `Psychometrics` object with samples of item parameter estimates stored in the `chain` field),\n","   - `\"de_jong_maximin\"`: maximizes the minimum across the tests of the mean across item parameters samples corrected by 1 standard deviations of the TIF (De Jong et al. (2009) approach. It requires a `Psychometrics` object with samples of item parameter estimates stored in the chain field.),\n","   - `\"custom\"`: only for siman solver, user customizable objective function,\n","   - `\"\"`: no objective. \n"," - `?obj_points`: Required for each objective which uses the TIF. For each test group, the vector of ability points the TIF is computed at. If more than one ability points is provided, the solver tries to maximize the lowest TIF across points.\n","  - `?obj_targets`: Only for the MINIMAX model and required for that objective. For each test group and ability point, the targets the TIF must approach.\n"," - `?obj_aux_int`: For randomized objectives (cc_maximin, de_jong_maximin and soyster_maximin) the number of item parameter samples (i.e. the length of the item parameter estimates chain).\n"," - `?obj_aux_float`: For the cc_maximin model, the quantile.\n"," - `?categories`: The categorical variables to summarize in the printed results.\n","\n","- 🔣__Item Bank__ (required):\n","  A data frame (`DataFrames.DataFrame` object) which contains the features of the items (item parameters, expected scores, item type, friend sets, enemy sets, and other categorical or quantitative variables).\n","- 🔢__Overlap Matrix__ (optional):\n","  A $sum(T) \\times sum(T)$ matrix containing the maximum overlap between test forms.\n","- 🔣__Categorical and Quantitative Constraints__ (optional):\n","  A data frame (`DataFrames.DataFrame` object) with specific columns (group, var, value, min, max, and weight) which contains the upper and lower bounds of the sum of quantitative variables and on number of items presenting a specific value of a categorical variable. For the siman solver, also the weight for each constraint can be specified using the column \"weight\".\n","- 📝__A license for one commercial solvers__ (optional 😎):\n","  If the `JuMP` package is used to solve the ATA model, several open-source and commercial solvers are available. If, for example, the CPLEX solver is selected, a valid license and the `CPLEX.jl` package must be installed and working in the machine in which this notebook is run. In this tutorial, both the pure Julia ATA solver `siman` and the open-source `Cbc` mixed-integer linear programming (MILP) solver are used to solve the same model.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"PV5lJEnkczAc"},"source":["## Build your First ATA Model\n","\n","Once all the required model specifications and item features have been collected, we are ready to build our ATA model.\n","\n","In this example a classical MAXIMIN model with test content and structure constraints is solved.\n","By the MAXIMIN model, the solver seeks the combination of items which produce the maximum TIF (inverse of the expected test measurement precision).\n","If more than one test must be assembled, the solver tries to maximize the lower TIF across tests.\n","\n","We want to assemble 30 test forms divided into 3 groups of equal size (10 tests per group).\n","This means that the 10 tests belonging to a certain group share the same content features and they are parallel with respect to the psychometric properties (TIF, ICFs/expected score).\n","\n","The IRT model underlying the item parameters is the \"1PL\", so the difficulty parameter \"b\" is provided as a column in the item bank.\n","The items can belong to friend sets as indicated in the column \"UNIT\".\n","On the other hand, the column \"ENEMY_SET\" contains the names of the enemy sets.\n","The expected score of each item is provided as the column \"PROP_CORR\".\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_gALheXo80Uz"},"source":["### ATA Settings and Item Bank\n","\n","To initialize the an ATA model, the function `start_ata()` must be called.\n","The `start_ata()` function has the following arguments:\n"," - (method 1)`settings`: an `InputSettings` object containing the ATA settings and generic specifications\\\n"," alternatively:\n"," - (method 2)`settings_file`: the name of a file containing an `InputSettings` object assigned to a variable named `Inputs`.\n","\n","\n"," - (method 1)`bank`: a data frame \n"," alternatively:\n"," - (method 2)`bank_file` and `bank_delim`, the name of a csv file containing the item bank data and the delimitator of the values, respectively.\n","\n","The item bank can be passed to the ATA model in a separate step using the function `add_bank!(ata_model)` which has the arguments `bank`, `bank_file`, and `bank_delim` as well. \n","\n","Let's use the first method for the settings and the second method for the item bank:"]},{"cell_type":"code","metadata":{"id":"LwudjeGx4tFh","executionInfo":{"status":"ok","timestamp":1619127245401,"user_tz":-120,"elapsed":4309,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}}},"source":["using ATA\n","settings = ATA.InputSettings(\n","  n_groups = 3,\n","  groups = [\"A\", \"B\", \"C\"],\n","  T = [10,10,10],\n","  n_items = 366,\n","  irt_model = \"1PL\",\n","  irt_parametrization = \"at-ab\",\n","  irt_D = 1.0,\n","  enemy_sets_var = [\"ENEMY_SET\"],\n","  friend_sets_var = [\"UNIT\"],\n","  item_use_min = fill(0, 366),\n","  item_use_max = fill(8, 366),\n","  length_min = [36, 36, 36],\n","  length_max = [40, 40, 40],\n","  length_weight = [1.0, 1.0, 1.0],\n","  expected_score_var = [\"PROP_CORR\", \"PROP_CORR\", \"PROP_CORR\"],\n","  expected_score_pts =  [[0.0], [0.0], [0.0]],\n","  expected_score_min = [[0.50], [0.50], [0.50]],\n","  expected_score_max = [[0.57], [0.57], [0.57]],\n","  obj_type = \"maximin\", \n","  obj_points = [[-0.60], [0.30], [0.60]],\n","  categories = [\"UNIT\", \"CAT_1\", \"CAT_2\", \"CAT_3\", \"CAT_4\", \"CAT_5_6\", \"CAT_5\", \"CAT_6\"]\n",");"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h3gDeia-d4f3"},"source":["We download the item bank file from the examples folder of the ATA.jl repository\n"]},{"cell_type":"code","metadata":{"id":"LagisI92G0uM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619127245670,"user_tz":-120,"elapsed":2334,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"9fdcdba1-da6b-40df-a3a3-eeee5977a4af"},"source":["using HTTP\n","bank =  HTTP.request(\"GET\",\"https://raw.githubusercontent.com/giadasp/ATA.jl/master/examples/data/bank.csv\")\n","write(\"bank.csv\", bank.body)"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21390"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"th5Bcl9xKbDZ"},"source":["(Method 1) Otherwise, you can load the data frame by using the CSV package and using the Statistics package we can easily summarize the variables."]},{"cell_type":"code","metadata":{"id":"I63TZGmOKWlc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619127245673,"user_tz":-120,"elapsed":1640,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"2e335717-06b1-4a1b-fc58-c995e73e2fc8"},"source":["using CSV\n","using DataFrames\n","using StatsBase\n","bank = CSV.read(\"bank.csv\", delim=';', DataFrames.DataFrame)\n","println(describe(bank))\n","println(\"Frequencies of CAT_1\")\n","println(countmap(bank[!,:CAT_1]))\n","println(\"Frequencies of CAT_2\")\n","println(countmap(bank[!,:CAT_2]))\n","println(\"Frequencies of CAT_3\")\n","println(countmap(bank[!,:CAT_3]))\n","println(\"Frequencies of CAT_4\")\n","println(countmap(bank[!,:CAT_4]))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["\u001b[1m13×7 DataFrame\u001b[0m\n","\u001b[1m Row \u001b[0m│\u001b[1m variable  \u001b[0m\u001b[1m mean      \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype                 \u001b[0m\n","\u001b[1m     \u001b[0m│\u001b[90m Symbol    \u001b[0m\u001b[90m Union…    \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Union… \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m Type                   \u001b[0m\n","─────┼──────────────────────────────────────────────────────────────────────────────────\n","   1 │ ITEM_ID    183.5      1        183.5   366             0  Int64\n","   2 │ UNIT_ALL  \u001b[90m           \u001b[0m U_1     \u001b[90m        \u001b[0m U_99            0  String\n","   3 │ UNIT      \u001b[90m           \u001b[0m U_116   \u001b[90m        \u001b[0m U_86          186  Union{Missing, String}\n","   4 │ ENEMY_SET \u001b[90m           \u001b[0m ES_1    \u001b[90m        \u001b[0m ES_9          191  Union{Missing, String}\n","   5 │ CAT_1     \u001b[90m           \u001b[0m D_1     \u001b[90m        \u001b[0m D_4             0  String\n","   6 │ CAT_2     \u001b[90m           \u001b[0m CAT_2_1 \u001b[90m        \u001b[0m CAT_2_3         0  String\n","   7 │ CAT_3     \u001b[90m           \u001b[0m CAT_3_1 \u001b[90m        \u001b[0m CAT_3_5         0  String\n","   8 │ CAT_4      0.204918   0        0.0     1               0  Int64\n","   9 │ CAT_5_6   \u001b[90m           \u001b[0m A_BC    \u001b[90m        \u001b[0m S_B             0  String\n","  10 │ CAT_5     \u001b[90m           \u001b[0m A       \u001b[90m        \u001b[0m S               0  String\n","  11 │ CAT_6     \u001b[90m           \u001b[0m A       \u001b[90m        \u001b[0m C               0  String\n","  12 │ b          0.0434317  -3.045   -0.147  4.349           0  Float64\n","  13 │ PROP_CORR  0.510038   0.029    0.5265  0.912           0  Float64\n","Frequencies of CAT_1\n","Dict(\"D_3\" => 154, \"D_1\" => 80, \"D_4\" => 55, \"D_2\" => 77)\n","Frequencies of CAT_2\n","Dict(\"CAT_2_2\" => 155, \"CAT_2_3\" => 17, \"CAT_2_1\" => 194)\n","Frequencies of CAT_3\n","Dict(\"CAT_3_3\" => 5, \"CAT_3_4\" => 38, \"CAT_3_5\" => 130, \"CAT_3_1\" => 16, \"CAT_3_2\" => 177)\n","Frequencies of CAT_4\n","Dict(0 => 291, 1 => 75)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0QH-W0ITZfD3"},"source":["We are ready to initialize the model."]},{"cell_type":"code","metadata":{"id":"7SfCza0jZhkc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619127256696,"user_tz":-120,"elapsed":10591,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"1526ff2d-c647-4045-d72a-418d834e9859"},"source":["ata_model = start_ata(settings = settings, bank_file = \"bank.csv\", bank_delim = \";\")"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ATA.MaximinModel(ATA.Settings(366, 266, \u001b[1m366×14 DataFrame\u001b[0m\n","\u001b[1m Row \u001b[0m│\u001b[1m ITEM_ID \u001b[0m\u001b[1m UNIT_ALL \u001b[0m\u001b[1m UNIT    \u001b[0m\u001b[1m ENEMY_SET \u001b[0m\u001b[1m CAT_1  \u001b[0m\u001b[1m CAT_2   \u001b[0m\u001b[1m CAT_3   \u001b[0m\u001b[1m CAT_4 \u001b[0m\u001b[1m\u001b[0m ⋯\n","\u001b[1m     \u001b[0m│\u001b[90m Int64   \u001b[0m\u001b[90m String   \u001b[0m\u001b[90m String? \u001b[0m\u001b[90m String?   \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m\u001b[0m ⋯\n","─────┼──────────────────────────────────────────────────────────────────────────\n","   1 │       1  U_254     U_254    ES_37      D_3     CAT_2_1  CAT_3_2      0  ⋯\n","   2 │       2  U_254     U_254   \u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_2      0\n","   3 │       3  U_254     U_254   \u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_2      0\n","   4 │       4  U_256    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_2     CAT_2_1  CAT_3_5      0\n","   5 │       5  U_257    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_4      0  ⋯\n","   6 │       6  U_258    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_4     CAT_2_1  CAT_3_5      0\n","   7 │       7  U_259    \u001b[90m missing \u001b[0m ES_5       D_2     CAT_2_1  CAT_3_5      0\n","   8 │       8  U_260     U_260    ES_17      D_3     CAT_2_2  CAT_3_2      0\n","   9 │       9  U_260     U_260   \u001b[90m missing   \u001b[0m D_3     CAT_2_2  CAT_3_5      0  ⋯\n","  10 │      10  U_261    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_1     CAT_2_2  CAT_3_2      1\n","  11 │      11  U_262    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_2  CAT_3_5      0\n","  ⋮  │    ⋮        ⋮         ⋮         ⋮        ⋮        ⋮        ⋮       ⋮    ⋱\n"," 357 │     357  U_151    \u001b[90m missing \u001b[0m ES_32      D_3     CAT_2_1  CAT_3_4      1\n"," 358 │     358  U_211    \u001b[90m missing \u001b[0m ES_32      D_3     CAT_2_1  CAT_3_4      0  ⋯\n"," 359 │     359  U_209    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_5      1\n"," 360 │     360  U_264    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_2      1\n"," 361 │     361  U_264    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_2      0\n"," 362 │     362  U_264    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_2      0  ⋯\n"," 363 │     363  U_153    \u001b[90m missing \u001b[0m ES_32      D_3     CAT_2_1  CAT_3_4      0\n"," 364 │     364  U_97     \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_2     CAT_2_1  CAT_3_5      0\n"," 365 │     365  U_185    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_3     CAT_2_1  CAT_3_5      0\n"," 366 │     366  U_236    \u001b[90m missing \u001b[0m\u001b[90m missing   \u001b[0m D_4     CAT_2_2  CAT_3_2      1  ⋯\n","\u001b[36m                                                  6 columns and 345 rows omitted\u001b[0m, ATA.IRT(\"1PL\", \u001b[1m366×1 DataFrame\u001b[0m\n","\u001b[1m Row \u001b[0m│\u001b[1m b       \u001b[0m\n","\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\n","─────┼─────────\n","   1 │  -2.37\n","   2 │  -0.2\n","   3 │  -0.21\n","   4 │  -0.881\n","   5 │   1.862\n","   6 │  -0.828\n","   7 │  -1.064\n","   8 │   0.578\n","   9 │   1.199\n","  10 │   2.861\n","  11 │  -0.566\n","  ⋮  │    ⋮\n"," 357 │   0.517\n"," 358 │   0.962\n"," 359 │   0.227\n"," 360 │   1.435\n"," 361 │   2.709\n"," 362 │   2.301\n"," 363 │   1.322\n"," 364 │  -0.217\n"," 365 │   1.639\n"," 366 │   3.152\n","\u001b[36m345 rows omitted\u001b[0m, \"at-ab\", 1.0, [0.0, 1.0], [0.0], [0.0]), [[-6.0, 6.0]], Vector{Bool}[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  …  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 3, 30, [10, 10, 10], ATA.FriendSets([:UNIT, :SINGLE_fs], [\"U_254\", \"U_260\", \"U_126\", \"U_20\", \"U_194\", \"U_130\", \"U_147\", \"U_55\", \"U_85\", \"U_201\"  …  \"357\", \"358\", \"359\", \"360\", \"361\", \"362\", \"363\", \"364\", \"365\", \"366\"], [3, 2, 2, 2, 3, 2, 2, 3, 2, 2  …  1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [[1, 2, 3], [8, 9], [14, 15], [17, 18], [21, 22, 23], [25, 26], [35, 36], [38, 39, 40], [43, 44], [47, 48]  …  [357], [358], [359], [360], [361], [362], [363], [364], [365], [366]]), ATA.EnemySets([:ENEMY_SET], [\"ES_37\", \"ES_5\", \"ES_17\", \"ES_34\", \"ES_18\", \"ES_14\", \"ES_20\", \"ES_3\", \"ES_41\", \"ES_31\"  …  \"ES_28\", \"ES_13\", \"ES_25\", \"ES_4\", \"ES_38\", \"ES_30\", \"ES_36\", \"ES_16\", \"ES_22\", \"ES_32\"], [[1, 25, 46, 202], [7, 266, 281], [8, 43, 70], [12, 30, 91, 222, 232, 248, 274, 294], [14, 35, 52], [19, 186], [24, 130, 174, 191], [27, 81, 177], [28, 115, 133, 163], [29, 41, 95, 151]  …  [211, 226, 259], [225, 285, 295, 333], [235, 269, 282, 289, 329, 330, 331, 332], [301, 312], [303, 321], [323, 324], [325, 326, 327], [334, 335], [337, 338, 339], [355, 356, 357, 358, 363]]), ATA.ItemUse(Int64[], [8, 8, 8, 8, 8, 8, 8, 8, 8, 8  …  8, 8, 8, 8, 8, 8, 8, 8, 8, 8]), [0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[1, 0, 0]), ATA.Constraint[ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])  …  ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), ATA.Constraint(36, 40, ATA.ExpectedScore(:PROP_CORR, [0.852 0.526 … 0.395 0.163], [0.5], [0.57], [0.0]), Symbol[], Float64[], Float64[], [-1.0 -1.0 … -1.0 -1.0; 1.0 1.0 … 1.0 1.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], [-36.0, 40.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])], ATA.MaximinObjective(\"maximin\", \"max\", ATA.MaximinObjectiveCore[ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([-0.6], Matrix{Float64}(undef, 0, 0))  …  ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0)), ATA.MaximinObjectiveCore([0.6], Matrix{Float64}(undef, 0, 0))]), ATA.Output([:UNIT, :CAT_1, :CAT_2, :CAT_3, :CAT_4, :CAT_5_6, :CAT_5, :CAT_6], Symbol[], Function[], Matrix{Float64}(undef, 0, 0), 0.0, Float64[], Float64[], 0.0, ATA.Neighbourhood[], [[\"success\", \"- InputSettings object loaded.\\n\"], [\"success\", \"- Item bank file loaded.\\n\"], [\"success\", \"- IRT item parameters loaded.\\n\"], [\"success\", \"- IRT item parameters loaded.\\n\"], [\"success\", \"- Minimum length of tests constrained.\\n\"], [\"success\", \"- Maximum length of tests constrained.\\n\"], [\"success\", \"- 266 friend sets added.\\n\"], [\"success\", \"- 48 enemy sets added and constrained.\\n\"], [\"success\", \"- Expected score variable loaded.\\n\"], [\"success\", \"- Lower bounds for expected score loaded.\\n\"], [\"success\", \"- Upper bounds for expected score loaded.\\n\"], [\"success\", \"- Expected scores (ICFs) based on IRT parameters computed.\\n\"], [\"success\", \"- Expected Score constrained.\\n\"], [\"success\", \"- Maximum item use constrained.\\n\"], [\"success\", \"- Optimization points loaded.\\n\"], [\"success\", \"- Categories for output loaded.\\n\"], [\"success\", \"- ASSEMBLE 30 FORMS DIVIDED INTO 3 GROUPS.\\n\"]]))"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"XGAaeYvracIQ"},"source":["### Load the Categorical Constraints and Constraints on Sum of Quantitative Variables \n","\n","The number of items having a certain content feature (categorical variable), e.g. CAT_1, CAT_2, and CAT_3 in our item bank, can be constrained to be in a limited interval for each test group.\n","Moreover, sometimes, it can be helpful to limit the total number of words displayed in a test form.\n","This value is equal to the sum of the words (quantitative variable) in the items selected to be in the test form.\n","For example, CAT_4 is a quantitative variable taking the values 0 and 1.\n","\n","To add these kinds of specifications we need to use a data frame with specific columns.\n","Thus, we first create an empty data frame with the desired structure and then we populate it with some examples of constraints.\n","At the end, we will download the data frame used in the examples of ATA.jl repository and we will add it to the model with the `add_constraints!` function.\n"]},{"cell_type":"code","metadata":{"id":"eNOyOveQdrqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619127257544,"user_tz":-120,"elapsed":9418,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"a7c0bbfa-982b-4542-a91b-0d5794875955"},"source":["# Create an empty constraints dataframe\n","constraints_example = DataFrame(\n","  group = Int64[],\n","  var = String[],\n","  value = Union{Missing,String}[],\n","  min = Int64[],\n","  max = Int64[],\n","  weight = Float64[]\n",")\n","# Populate it with a constraint on CAT_1 on the tests in group 1\n","push!(constraints_example, [1, \"CAT_1\", \"D_3\", 10, 15, 1.0])\n","# Populate it with a constraint on CAT_4 on the tests in group 2 (value is missing because CAT_4 is a quantitative variable)\n","push!(constraints_example, [2, \"CAT_4\", missing, 2, 10, 1.0])\n","println(\"Constraints example\")\n","println(constraints_example)\n","\n","# Download dataframe from the repo\n","constraints =  HTTP.request(\"GET\",\"https://raw.githubusercontent.com/giadasp/ATA.jl/master/examples/Constraints.csv\")\n","write(\"constraints.csv\", constraints.body)\n","constraints = CSV.read(\"constraints.csv\", delim = ';', DataFrames.DataFrame);\n","println(\"Constraints\")\n","println(constraints)\n","\n","# Add the constraints to the model (Method 1)\n","add_constraints!(ata_model, constraints = constraints)\n","# or Method 2 (do not run)\n","# add_constraints!(ata_model, constraints_file = \"constraints.csv\", constraints_delim = \";\")\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Constraints example\n","\u001b[1m2×6 DataFrame\u001b[0m\n","\u001b[1m Row \u001b[0m│\u001b[1m group \u001b[0m\u001b[1m var    \u001b[0m\u001b[1m value   \u001b[0m\u001b[1m min   \u001b[0m\u001b[1m max   \u001b[0m\u001b[1m weight  \u001b[0m\n","\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String \u001b[0m\u001b[90m String? \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Float64 \u001b[0m\n","─────┼───────────────────────────────────────────────\n","   1 │     1  CAT_1   D_3         10     15      1.0\n","   2 │     2  CAT_4  \u001b[90m missing \u001b[0m     2     10      1.0\n","Constraints\n","\u001b[1m32×6 DataFrame\u001b[0m\n","\u001b[1m Row \u001b[0m│\u001b[1m group \u001b[0m\u001b[1m var     \u001b[0m\u001b[1m value   \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m weight  \u001b[0m\n","\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m String  \u001b[0m\u001b[90m Int64?  \u001b[0m\u001b[90m Int64?  \u001b[0m\u001b[90m Float64 \u001b[0m\n","─────┼────────────────────────────────────────────────────\n","   1 │     1  CAT_1    D_1            6       11      1.0\n","   2 │     1  CAT_1    D_2            5        9      1.0\n","   3 │     1  CAT_1    D_3           10       20      1.0\n","   4 │     1  CAT_1    D_4            4        8      1.0\n","   5 │     2  CAT_1    D_1            6       11      1.0\n","   6 │     2  CAT_1    D_2            3        7      1.0\n","   7 │     2  CAT_1    D_3           10       20      1.0\n","   8 │     2  CAT_1    D_4            3        7      1.0\n","   9 │     3  CAT_1    D_1            6       11      1.0\n","  10 │     3  CAT_1    D_2            3        7      1.0\n","  11 │     3  CAT_1    D_3           10       20      1.0\n","  12 │     3  CAT_1    D_4            3        7      1.0\n","  13 │     1  CAT_2    CAT_2_3        1 \u001b[90m missing \u001b[0m     1.0\n","  14 │     2  CAT_2    CAT_2_3        1 \u001b[90m missing \u001b[0m     1.0\n","  15 │     3  CAT_2    CAT_2_3        1 \u001b[90m missing \u001b[0m     1.0\n","  16 │     1  CAT_3    CAT_3_4        1        5      1.0\n","  17 │     2  CAT_3    CAT_3_4        1        5      1.0\n","  18 │     3  CAT_3    CAT_3_4        1        5      1.0\n","  19 │     1  CAT_5_6  G_A     \u001b[90m missing \u001b[0m      17      1.0\n","  20 │     1  CAT_5_6  F_A     \u001b[90m missing \u001b[0m      25      1.0\n","  21 │     1  CAT_5_6  A_BC    \u001b[90m missing \u001b[0m       0      1.0\n","  22 │     1  CAT_5_6  A_C     \u001b[90m missing \u001b[0m       0      1.0\n","  23 │     1  CAT_5_6  S_B     \u001b[90m missing \u001b[0m       0      1.0\n","  24 │     2  CAT_5_6  G_A     \u001b[90m missing \u001b[0m      13      1.0\n","  25 │     2  CAT_5_6  F_A     \u001b[90m missing \u001b[0m      21      1.0\n","  26 │     2  CAT_5    A       \u001b[90m missing \u001b[0m       9      1.0\n","  27 │     2  CAT_5_6  S_B     \u001b[90m missing \u001b[0m       0      1.0\n","  28 │     3  CAT_5_6  G_A     \u001b[90m missing \u001b[0m      13      1.0\n","  29 │     3  CAT_5_6  F_A     \u001b[90m missing \u001b[0m      21      1.0\n","  30 │     3  CAT_5_6  A_BC    \u001b[90m missing \u001b[0m       3      1.0\n","  31 │     3  CAT_5_6  A_C     \u001b[90m missing \u001b[0m       0      1.0\n","  32 │     3  CAT_5_6  S_B     \u001b[90m missing \u001b[0m       7      1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3hqC5rFPWV6I"},"source":["### Load the Overlap Matrix\n","\n","Like the item bank and the constraints data frame, we can add the constraints on the maximum number of overlapping items by using the two methods (matrix vs file name).\n","We create a matrix of size $30 \\times 30$ with values equal to 14."]},{"cell_type":"code","metadata":{"id":"G2A1N2QIWjRZ","executionInfo":{"status":"ok","timestamp":1619127257559,"user_tz":-120,"elapsed":6482,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}}},"source":["# Cretate the overlap matrix\n","overlap = 14 .* ones(30, 30)\n","\n","# Add the overlap constraints to the model (Method 1)\n","add_overlap!(ata_model, overlap = overlap)\n","\n","# or Method 2 (do not run)\n","# add_overlap!(ata_model, overlap_file = \"overlap.csv\", overlap_delim)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHe097k5cydQ"},"source":["### Add the Objective Function\n","\n","Finally, we compute the item information functions and we add the MAXIMIN TIF objective function to the model. "]},{"cell_type":"code","metadata":{"id":"HhQ_6YGYZT0q","executionInfo":{"status":"ok","timestamp":1619127257562,"user_tz":-120,"elapsed":5759,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}}},"source":["add_obj_fun!(ata_model)"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hWZjyW_Tddca"},"source":["## Assemble the Model\n","\n","Let's assemble the model. We choose the pure Julia siman solver. The description of the hyperparameters is given just after each keyword."]},{"cell_type":"code","metadata":{"id":"jfAuR-yQeJ-R","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1619131407162,"user_tz":-120,"elapsed":403321,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}},"outputId":"8567d079-5e15-4279-9aea-b37acedc8144"},"source":["assemble!(\n","  ata_model,\n","  solver = \"siman\",\n","  start_temp = 0.01;\n","  # Default: `0.1`. Values:  `[0, Inf]`. \n","  # Starting temperature, set to minimum for short journeys (if 0 worse solutions will never be accepted).\n","\n","  geom_temp = 0.1,\n","  # Default: `0.1`. Values:  `[0, Inf)`.\n","  # Decreasing geometric factor.\n","\n","  n_item_sample = Inf,\n","  # Default: 1. Values: `[1, Inf]`. \n","  # Number of items to alter. Set to minimum for a shallow analysis, \n","  # set to maximum for a deep analysis of the neighbourhoods.\n","\n","  n_test_sample = Inf,\n","  # Default: 1. Values: `[1, Inf]`. \n","  # Number of tests to alter. Set to minimum for a shallow analysis, set to maximum for a deep analysis of the neighbourhoods.\n","\n","  opt_feas = 0.9,\n","  # Default: 0.0. Values: `[0, Inf)`. \n","  # Optimality/feasibility balancer, if 0 only feasibility of solution is analysed. Viceversa, if 1, only optimality is considered (uncontrained model). All the other values are accepted but produce uninterpretable results.\n","\n","  n_fill = 1,\n","  # Default: 1. Values: `[0, Inf)`.\n","  # Number of fill-up phases, usually 1 is sufficient, if start_temp is high it can be higher. \n","  # If a starting_design is supplied, it should be set to 0.\n","\n","  verbosity = 1,\n","  # Default: 2. Values: `1` (minimal), `2` (detailed).\n","  # Verbosity level. In the console '+' stands for improvement, '_' for accepting worse solution.\n","  # The dots are the fill-up improvement steps.\n","\n","  #! Termination criteria: \n","\n","  max_time = 500.0,\n","  # Default: `1000.0`. Values: `[0, Inf)`.\n","  # Time limit in seconds.\n","\n","  max_conv = 10,\n","  # Default: `2`. Values: `[1, Inf)`. \n","  # Maximum convergence, stop when, after max_conv rounds no improvements have been found. \n","  # Set to minimum for shallow analysis, increase it for deep analysis of neighbourhoods.\n","\n","  feas_nh = 1,\n","  # Default: `0`. Values: `[1, Inf)`. \n","  # Maximum number of Feasibility neighbourhoods to explore, set to the minimum if the model is small or not highly constrained.\n","\n","  opt_nh = Inf\n","  # Default: `5`. Values: `[1, Inf)`. \n","  # Maximum number of Optimality neighbourhoods to explore, set to the minimum if the model is highly constrained.\n",")"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Starting solution: \n","\n","  f : 183.000\n","  infeas :\t[  63.0  63.0  63.0  63.0  63.0  63.0  63.0  63.0  63.0  63.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0  60.0    ]\n","  overlaps :\t[    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    ]\n","  item use :\t[    0.0    ]\n","Fill-up starting...\n",".................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................-Test 5 filled up with 40.0 items, \n",".....-Test 7 filled up with 40.0 items, \n",".....................-Test 8 filled up with 40.0 items, \n","......-Test 2 filled up with 40.0 items, \n","......-Test 4 filled up with 40.0 items, \n",".......-Test 20 filled up with 40.0 items, \n","......-Test 13 filled up with 40.0 items, \n",".........-Test 19 filled up with 40.0 items, \n","....-Test 22 filled up with 40.0 items, \n",".........-Test 30 filled up with 40.0 items, \n","....-Test 11 filled up with 40.0 items, \n","....-Test 1 filled up with 40.0 items, \n","....-Test 3 filled up with 40.0 items, \n","....-Test 6 filled up with 40.0 items, \n",".....-Test 14 filled up with 40.0 items, \n","....-Test 9 filled up with 40.0 items, \n","....-Test 10 filled up with 40.0 items, \n",".....-Test 12 filled up with 40.0 items, \n","....-Test 15 filled up with 40.0 items, \n","....-Test 16 filled up with 40.0 items, \n",".....-Test 17 filled up with 40.0 items, \n",".....-Test 18 filled up with 40.0 items, \n","....-Test 21 filled up with 40.0 items, \n","....-Test 23 filled up with 40.0 items, \n","....-Test 24 filled up with 40.0 items, \n",".....-Test 25 filled up with 40.0 items, \n",".....-Test 26 filled up with 40.0 items, \n",".....-Test 27 filled up with 40.0 items, \n","....-Test 29 filled up with 40.0 items, \n","....-Test 28 filled up with 40.0 items, \n","End of fill-up\n","Feasible solution not found in fill-up\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"],"name":"stdout"},{"output_type":"error","ename":"LoadError","evalue":"ignored","traceback":["TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mBoundsError: attempt to access 30-element Vector{Int64} at index [31]\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mgetindex\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4marray.jl:801\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [2] \u001b[0m\u001b[1manalyse_NH\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mNH_start\u001b[39m::\u001b[0mATA.Neighbourhood, \u001b[90mata_model\u001b[39m::\u001b[0mATA.MaximinModel; \u001b[90mfF\u001b[39m::\u001b[0mBool, \u001b[90mn_fill\u001b[39m::\u001b[0mInt64, \u001b[90mopt_feas\u001b[39m::\u001b[0mFloat64, \u001b[90mmax_conv\u001b[39m::\u001b[0mInt64, \u001b[90mstart_temp\u001b[39m::\u001b[0mFloat64, \u001b[90mgeom_temp\u001b[39m::\u001b[0mFloat64, \u001b[90mn_item_sample\u001b[39m::\u001b[0mFloat64, \u001b[90mn_test_sample\u001b[39m::\u001b[0mFloat64, \u001b[90mverbosity\u001b[39m::\u001b[0mInt64, \u001b[90mstart_time\u001b[39m::\u001b[0mFloat64, \u001b[90mmax_time\u001b[39m::\u001b[0mFloat64\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mATA\u001b[39m \u001b[90m~/.julia/packages/ATA/evOpG/src/evaluate_nh/\u001b[39m\u001b[90;4mmaximin.jl:155\u001b[0m\n     [3] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m~/.julia/packages/ATA/evOpG/src/\u001b[39m\u001b[90;4msimAn.jl:146\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [4] \u001b[0m\u001b[1m(::ATA.var\"#132#142\"{String, Float64, Float64, Int64, Float64, Float64, Float64, Int64, ATA.MaximinModel, Vector{Int64}, Float64})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mR\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m, \u001b[90mlo\u001b[39m::\u001b[0mInt64, \u001b[90mhi\u001b[39m::\u001b[0mInt64\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mATA\u001b[39m \u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mmacros.jl:306\u001b[0m\n     [5] \u001b[0m\u001b[1m#160\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mmacros.jl:87\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [6] \u001b[0m\u001b[1mrun_work_thunk\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mthunk\u001b[39m::\u001b[0mDistributed.var\"#160#162\"\u001b[90m{UnitRange{Int64}, ATA.var\"#132#142\"{String, Float64, Float64, Int64, Float64, Float64, Float64, Int64, ATA.MaximinModel, Vector{Int64}, Float64}, Vector{Int64}}\u001b[39m, \u001b[90mprint_error\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[36mDistributed\u001b[39m \u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:63\u001b[0m\n     [7] \u001b[0m\u001b[1mrun_work_thunk\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m/buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.6/Distributed/src/\u001b[39m\u001b[90;4mprocess_messages.jl:72\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [8] \u001b[0m\u001b[1m(::Distributed.var\"#96#98\"{Distributed.RemoteValue, Distributed.var\"#160#162\"{UnitRange{Int64}, ATA.var\"#132#142\"{String, Float64, Float64, Int64, Float64, Float64, Float64, Int64, ATA.MaximinModel, Vector{Int64}, Float64}, Vector{Int64}}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[36mDistributed\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mtask.jl:406\u001b[0m\n    Stacktrace:\n     [1] \u001b[0m\u001b[1msync_end\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mc\u001b[39m::\u001b[0mChannel\u001b[90m{Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90mBase\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mtask.jl:364\u001b[0m\n     [2] \u001b[0m\u001b[1m(::Distributed.var\"#159#161\"{ATA.var\"#132#142\"{String, Float64, Float64, Int64, Float64, Float64, Float64, Int64, ATA.MaximinModel, Vector{Int64}, Float64}, Vector{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mDistributed\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mtask.jl:383\u001b[0m","","Stacktrace:"," [1] sync_end(c::Channel{Any})","   @ Base ./task.jl:364"," [2] macro expansion","   @ ./task.jl:383 [inlined]"," [3] siman!(ata_model::ATA.MaximinModel; starting_design::Matrix{Float64}, results_folder::String, start_temp::Float64, geom_temp::Float64, max_time::Float64, max_conv::Int64, feas_nh::Int64, opt_nh::Float64, n_item_sample::Float64, n_test_sample::Float64, opt_feas::Float64, n_fill::Int64, verbosity::Int64, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})","   @ ATA ~/.julia/packages/ATA/evOpG/src/simAn.jl:137"," [4] assemble!(ata_model::ATA.MaximinModel; solver::String, starting_design::Matrix{Float64}, results_folder::String, start_temp::Float64, geom_temp::Float64, n_item_sample::Float64, n_test_sample::Float64, opt_feas::Float64, n_fill::Int64, max_time::Float64, max_conv::Int64, feas_nh::Int64, opt_nh::Float64, verbosity::Int64, optimizer_constructor::String, optimizer_attributes::Vector{Tuple{String, Int64}}, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})","   @ ATA ~/.julia/packages/ATA/evOpG/src/opt.jl:64"," [5] top-level scope","   @ In[36]:1"," [6] eval","   @ ./boot.jl:360 [inlined]"," [7] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)","   @ Base ./loading.jl:1094"]}]},{"cell_type":"markdown","metadata":{"id":"7gFFEM12nDas"},"source":["## Print Results\n","\n","As can be seen in the printed output, the solver didn't return a feasible solution (Feasibility > 0).\n","We can have an indepth look at the assembed tests using the function `print_results`.\n","It creates a file named \"results\" in the `results_folder`."]},{"cell_type":"markdown","metadata":{"id":"upW6X2JOozzv"},"source":[""]},{"cell_type":"code","metadata":{"id":"HG5yCvuznbkH","executionInfo":{"status":"ok","timestamp":1619129478494,"user_tz":-120,"elapsed":5311,"user":{"displayName":"Giada Spaccapanico Proietti","photoUrl":"","userId":"18003153862373929975"}}},"source":["print_results(ata_model; results_folder = \"results\")"],"execution_count":34,"outputs":[]}]}